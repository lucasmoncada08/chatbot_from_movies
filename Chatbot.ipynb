{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38247ffa",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7a454909",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import os\n",
    "from io import open\n",
    "import re\n",
    "import unicodedata\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c190da69",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "153c09a9",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64419c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c3527f46",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e6832e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "005a2f1c",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n"
     ]
    }
   ],
   "source": [
    "# display the movie lines\n",
    "def print_file_entry(file, n=5):\n",
    "    with open(file, 'rb') as moviefile:\n",
    "        entries = moviefile.readlines()\n",
    "    for entry in entries[:n]:\n",
    "        print(entry)\n",
    "        \n",
    "print_file_entry(\"movie_data/movie_lines.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c60c599f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6ea76c79",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\\n\"\n"
     ]
    }
   ],
   "source": [
    "print_file_entry(\"movie_data/movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be7a705",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c5380ef1",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "# split lines to organize lines with their corresponding fields\n",
    "def load_lines(file, fields):\n",
    "    lines = {}\n",
    "    with open(file, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "# split conversations to organize conversations into their corresponding fields\n",
    "def load_conversations(file, lines, fields):\n",
    "    conversations = []\n",
    "    with open(file, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "\n",
    "            conversObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                conversObj[field] = values[i]\n",
    "\n",
    "            line_id_pattern = re.compile('L[0-9]+')\n",
    "            line_ids = line_id_pattern.findall(conversObj['lineIDs'])\n",
    "\n",
    "            conversObj['lines'] = []\n",
    "            for lineId in line_ids:\n",
    "                conversObj['lines'].append(lines[lineId])\n",
    "            conversations.append(conversObj)\n",
    "    return conversations\n",
    "\n",
    "# get the sentence pairs to use as inputs and targets\n",
    "def extract_sentence_pairs(conversations):\n",
    "    qr_pairs = []\n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation['lines'])-1):\n",
    "            input_line = conversation['lines'][i][\"text\"].strip()\n",
    "            target_line = conversation['lines'][i+1]['text'].strip()\n",
    "            if input_line and target_line:\n",
    "                qr_pairs.append([input_line, target_line])\n",
    "    return qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0206f06",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "0b16a925",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "lines = {}\n",
    "conversations = []\n",
    "\n",
    "# fields corresponding to the order of the splits for lines and conversations\n",
    "lines_fields = ['lineID', 'characterID', 'movieID', 'character', 'text'] \n",
    "conversation_fields = ['character1ID', 'character2ID', 'movieID', 'lineIDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df6803f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a0d8858e",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "lines = load_lines(\"movie_data/movie_lines.txt\", lines_fields)\n",
    "\n",
    "conversations = load_conversations(\"movie_data/movie_conversations.txt\", lines, conversation_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cec86c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c743c6b6",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineID': 'L1045',\n",
       " 'characterID': 'u0',\n",
       " 'movieID': 'm0',\n",
       " 'character': 'BIANCA',\n",
       " 'text': 'They do not!\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['L1045']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4fc855",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "74198b2a",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'character1ID': 'u0',\n",
       " 'character2ID': 'u2',\n",
       " 'movieID': 'm0',\n",
       " 'lineIDs': \"['L194', 'L195', 'L196', 'L197']\\n\",\n",
       " 'lines': [{'lineID': 'L194',\n",
       "   'characterID': 'u0',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'BIANCA',\n",
       "   'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'},\n",
       "  {'lineID': 'L195',\n",
       "   'characterID': 'u2',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'CAMERON',\n",
       "   'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"},\n",
       "  {'lineID': 'L196',\n",
       "   'characterID': 'u0',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'BIANCA',\n",
       "   'text': 'Not the hacking and gagging and spitting part.  Please.\\n'},\n",
       "  {'lineID': 'L197',\n",
       "   'characterID': 'u2',\n",
       "   'movieID': 'm0',\n",
       "   'character': 'CAMERON',\n",
       "   'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7853e8df",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "faa5b9b1",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "qr_pairs = extract_sentence_pairs(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b173c1",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "d1af0bc2",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31c557d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4925d708",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "preset_tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "# vocabulary class\n",
    "class Vocab:\n",
    "    def __init__(self, preset_tokens):\n",
    "        self.lines = lines\n",
    "        self.conversations = conversations\n",
    "        self.trimmed = False\n",
    "        self.preset_tokens = preset_tokens\n",
    "        self.index_to_word = {i: word for i, word in enumerate(preset_tokens)} # initializing the preset tokens\n",
    "        self.word_to_index = {}\n",
    "        self.word_to_count = {}\n",
    "        self.num_words = len(preset_tokens)\n",
    "        \n",
    "    # iterate through words in a sentence to add them to the vocab\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    # handle a new word wrt the vocab\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word_to_index:\n",
    "            self.index_to_word[self.num_words] = word\n",
    "            self.word_to_index[word] = self.num_words\n",
    "            self.word_to_count[word] = 1\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word_to_count[word] += 1\n",
    "    \n",
    "    # get vocab for words above a certain minimum count threshold\n",
    "    def trim(self, min_count, preset_tokens):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        self.index_to_word = {i: word for i, word in enumerate(preset_tokens)} # initializing the preset tokens\n",
    "        self.word_to_index = {'<OUT>': preset_tokens.index('<OUT>')}\n",
    "        previous_word_to_count = self.word_to_count # storing this before reseting\n",
    "        self.word_to_count = {}\n",
    "        self.num_words = len(preset_tokens)\n",
    "        \n",
    "        for word, count in previous_word_to_count.items():\n",
    "            if count >= min_count:\n",
    "                self.add_word(word)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de393ee1",
   "metadata": {
    "gradient": {
     "id": "44ec7a6f",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "# convert unicode string to ascii string\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# creating function to tidy the text a bit\n",
    "def fix_contractions(text):\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve'\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re'\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    return text\n",
    "\n",
    "# cleaning the strings\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"[^A-Za-z.!?,']\", r\" \", s)\n",
    "    s = re.sub(r\"[.]\", r\" . \", s)\n",
    "    s = re.sub(r\"[!]\", r\" ! \", s)\n",
    "    s = re.sub(r\"[?]\", r\" ? \", s)\n",
    "    s = re.sub(r\"[,]\", r\" , \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s)\n",
    "    s = fix_contractions(s)\n",
    "    s = s.rstrip()\n",
    "    return s\n",
    "\n",
    "# construct covab and normalize strings\n",
    "def read_vocs(qr_pairs):\n",
    "    qr_pairs_normed = [[normalize_string(s) for s in pair] for pair in qr_pairs]\n",
    "    vocab = Vocab(preset_tokens)\n",
    "    return vocab, qr_pairs_normed\n",
    "    \n",
    "max_line_length = 20\n",
    "\n",
    "# check if the question and response are both below the mi\n",
    "def filter_pair(pair):\n",
    "    return len(pair[0].split(' ')) < max_line_length and len(pair[1].split(' ')) < max_line_length\n",
    "\n",
    "# filtering all the question and response\n",
    "def filter_qr_pairs(qr_pairs):\n",
    "    return [pair for pair in qr_pairs if filter_pair(pair)]\n",
    "\n",
    "# high-level utilize other functions to prepare the data\n",
    "def load_and_prepare_data(qr_pairs):\n",
    "    vocab, pairs = read_vocs(qr_pairs)\n",
    "    \n",
    "    pairs = filter_qr_pairs(pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        vocab.add_sentence(pair[0])\n",
    "        vocab.add_sentence(pair[1])\n",
    "    \n",
    "    return vocab, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a966c7b3",
   "metadata": {
    "gradient": {
     "execution_count": 101,
     "id": "55ea66bc",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well , i thought we would start with pronunciation , if that is okay with you .', 'not the hacking and gagging and spitting part . please .']\n",
      "['not the hacking and gagging and spitting part . please .', \"okay . . . then how 'bout we try out some french cuisine . saturday ? night ?\"]\n",
      "[\"you're asking me out . that is so cute . what is your name again ?\", 'forget it .']\n",
      "[\"no , no , it is my fault we didn't have a proper introduction\", 'cameron .']\n",
      "['gosh , if only we could find kat a boyfriend . . .', 'let me see what i can do .']\n",
      "[\"c'esc ma tete . this is my head\", \"right . see ? you're ready for the quiz .\"]\n",
      "['that is because it is such a nice one .', 'forget french .']\n",
      "['how is our little find the wench a date plan progressing ?', \"well , there's someone i think might be\"]\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', \"you're sweet .\"]\n"
     ]
    }
   ],
   "source": [
    "vocab, pairs = load_and_prepare_data(qr_pairs)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9bb283a",
   "metadata": {
    "gradient": {
     "execution_count": 107,
     "id": "c0d63692",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "# trim the words\n",
    "def trim_rare_words(vocab, pairs, min_word_occurence=6):\n",
    "    vocab.trim(min_word_occurence, preset_tokens)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        for i, word in enumerate(pair[0].split(' ')):\n",
    "            line = pair[0].split(' ')\n",
    "            if word not in vocab.word_to_index:\n",
    "                line[i] = '<OUT>'\n",
    "            pair[0] = ' '.join(line)    \n",
    "        for i, word in enumerate(pair[1].split(' ')):\n",
    "            line = pair[1].split(' ')\n",
    "            if word not in vocab.word_to_index:\n",
    "                line[i] = '<OUT>'\n",
    "            pair[1] = ' '.join(line)  \n",
    "    \n",
    "    return pairs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7786592",
   "metadata": {
    "gradient": {
     "execution_count": 108,
     "id": "b5551320",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [],
   "source": [
    "pairs = trim_rare_words(vocab, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f6ae89",
   "metadata": {
    "gradient": {
     "execution_count": 109,
     "id": "11051e54",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"okay . . . then how 'bout we try out some french <OUT> . saturday ? night ?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c5c7940",
   "metadata": {
    "gradient": {
     "id": "16496da8",
     "kernelId": "f874be3f-751b-47e0-a167-404af9510ba9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[6453,  669,   46,   40,   13],\n",
      "        [2010,    5, 1129,  156,   14],\n",
      "        [ 106,   95,   17,   19, 4548],\n",
      "        [  62,   19,   26, 3930,   17],\n",
      "        [  16, 4954,    2,   33,    1],\n",
      "        [  21,   83,   17,    1,    0],\n",
      "        [ 153,   84,    1,    0,    0],\n",
      "        [  40,    1,    0,    0,    0],\n",
      "        [ 245,    0,    0,    0,    0],\n",
      "        [ 203,    0,    0,    0,    0],\n",
      "        [ 106,    0,    0,    0,    0],\n",
      "        [ 136,    0,    0,    0,    0],\n",
      "        [  17,    0,    0,    0,    0],\n",
      "        [   1,    0,    0,    0,    0]])\n",
      "lengths: tensor([14,  8,  7,  6,  5])\n",
      "target_variable: tensor([[   6,    2,    6,   47,  265],\n",
      "        [  64,  152, 1717,  771,   17],\n",
      "        [  18,    1,   12,    5,   17],\n",
      "        [7054,    0,    6,   47,   17],\n",
      "        [ 532,    0,   63, 3930,   33],\n",
      "        [   4,    0,  158,   17,    1],\n",
      "        [ 348,    0,   51,    1,    0],\n",
      "        [  51,    0, 1878,    0,    0],\n",
      "        [   2,    0,   11,    0,    0],\n",
      "        [  17,    0,   51,    0,    0],\n",
      "        [   1,    0, 3034,    0,    0],\n",
      "        [   0,    0,  164,    0,    0],\n",
      "        [   0,    0,   19,    0,    0],\n",
      "        [   0,    0,    2,    0,    0],\n",
      "        [   0,    0,   33,    0,    0],\n",
      "        [   0,    0,    1,    0,    0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True,  True, False],\n",
      "        [ True, False,  True, False, False],\n",
      "        [ True, False,  True, False, False],\n",
      "        [ True, False,  True, False, False],\n",
      "        [ True, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False,  True, False, False]])\n",
      "max_target_length: 16\n"
     ]
    }
   ],
   "source": [
    "# return indices for words in the sentence in addition to EOS\n",
    "def indices_from_sentence(vocab, sentence):\n",
    "    return [vocab.word_to_index[word] for word in sentence.split(' ')] + [preset_tokens.index('<EOS>')]\n",
    "\n",
    "# adds zero padding to batches\n",
    "def zero_padding(indices_batch):\n",
    "    return list(itertools.zip_longest(*indices_batch, fillvalue = preset_tokens.index('<PAD>')))\n",
    "\n",
    "# \n",
    "def binary_matrix(batch):\n",
    "    mat = []\n",
    "    for i, seq in enumerate(batch):\n",
    "        mat.append([])\n",
    "        for token in seq:\n",
    "            if token == preset_tokens.index('<PAD>'):\n",
    "                mat[i].append(0)\n",
    "            else:\n",
    "                mat[i].append(1)\n",
    "    return mat\n",
    "\n",
    "# preparing input batch for input into the model\n",
    "def input_var(input_batch, vocab):\n",
    "    indices_batch = [indices_from_sentence(vocab, sentence) for sentence in input_batch]\n",
    "    lengths = torch.tensor([len(indices) for indices in indices_batch])\n",
    "    padded_batch = zero_padding(indices_batch)\n",
    "    padded_var = torch.LongTensor(padded_batch)\n",
    "    return padded_var, lengths\n",
    "\n",
    "# preparing output\n",
    "def output_var(output_batch, vocab):\n",
    "    indices_batch = [indices_from_sentence(vocab, sentence) for sentence in output_batch]\n",
    "    max_target_length = max([len(indices) for indices in indices_batch])\n",
    "    padded_list = zero_padding(indices_batch)\n",
    "    mask = binary_matrix(padded_list)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padded_var = torch.LongTensor(padded_list)\n",
    "    return padded_var, mask, max_target_length\n",
    "\n",
    "# prepare the pairs data into batches to use as training data\n",
    "def batch_to_train_data(vocab, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(' ')), reverse=True) # sorting the pairs by the length of the question\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = input_var(input_batch, vocab)\n",
    "    output, mask, max_target_length = output_var(output_batch, vocab)\n",
    "    return inp, lengths, output, mask, max_target_length\n",
    "    \n",
    "test_batch_size = 5\n",
    "batches = batch_to_train_data(vocab, [random.choice(pairs) for _ in range(test_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_length = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_length:\", max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5287687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<OUT>',\n",
       " '!',\n",
       " '<EOS>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_word = [vocab.index_to_word[target.item()] for target in target_variable[:, 1]]\n",
    "target_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec23fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ca14a64",
   "metadata": {},
   "source": [
    "# Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f191b",
   "metadata": {},
   "source": [
    "Here we will use a sequence to sequence model with an encoder and decoder RNN utilizing bi-directional Gated Recurrent Units (GRUs) and an attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd376366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers==1 else dropout),\n",
    "                          bidirectional=True)\n",
    "        \n",
    "    # forward pass through the model\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seq) # convert word indices to embeddings\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths) # pack padded batch sequences for RNN module\n",
    "        outputs, hidden = self.gru(packed, hidden) # forward pass through GRU\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs) # unpack padding\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:] # summing both of the bidirection GRU outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a6230a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        # account for invalid attention score function\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not a valid attention score function\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "            \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    \n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "    \n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # calculate the attention weight with the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        if self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        if self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "            \n",
    "        return F.softmax(attn_energies.t(), dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e4a4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout(0 if n_layers==1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attention(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden) # forward through unidirectional gru\n",
    "        \n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs) # calculate the attention weights from last gru ouput\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # get weighted sum as context layer\n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        \n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6adc7",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d67708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculating the negative log loss of padded sequences\n",
    "def mask_nll_loss(inp, target, mask):\n",
    "    n_total = mask.sum()\n",
    "    cross_entropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = cross_entropy.masked_select(mask).mean() # applying the mask to account for padding\n",
    "    loss = loss.to(device)\n",
    "    return loss, n_total.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6be0f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train(input_variable, lengths, target_variable, mask, max_target_length, encoder,\n",
    "          decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=max_line_length):\n",
    "    \n",
    "    # clear the gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # set variables to cuda\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    lengths = lengths.to('cpu')\n",
    "    \n",
    "    loss = 0\n",
    "    losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    # forward pass through the encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "    \n",
    "    # create initial decoder input\n",
    "    decoder_input = torch.LongTensor([[preset_tokens.index('<SOS>') for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    \n",
    "    # set initial decoder hidden state to encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    # decide on using teacher forcing in this iteration\n",
    "    use_teacher_forcing = True if random.random() < tracher_forcing_ratio else False\n",
    "    \n",
    "    # forward batch of sequences through the decoder one step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for target in range(max_target_lengths):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_variable[target].view(1, -1) # use teacher forcing\n",
    "            mask_loss, n_total = mask_nll_loss(decoder_output, target_variable[target], mask[target])\n",
    "            loss += mask_loss\n",
    "            losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    else:\n",
    "        for target in range(max_target_lengths):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            mask_loss, n_total = mask_nll_loss(decoder_output, target_variable[target], mask[target])\n",
    "            loss += mask_loss\n",
    "            losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    \n",
    "    loss.backward() # backward propogation\n",
    "    \n",
    "    # gradient clipping\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    # adjust the model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbcc9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_iters(model_name, vocab, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                    embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, \n",
    "                    print_every, save_every, clip, load_filename):\n",
    "    \n",
    "    # load batches for each iteration\n",
    "    training_batches = [batch_to_train_data(vocab, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                        for _ in range(n_iteration)]\n",
    "    \n",
    "    start_iteration = 1\n",
    "    losses = 0\n",
    "    if load_filename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "        \n",
    "    # training loop\n",
    "    print('Training...')\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        input_variable, lengths, target_variable, mask, max_target_length = training_batch\n",
    "        \n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_length, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        losses += loss\n",
    "        \n",
    "        # print training progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = losses / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration/n_iteration*100, print_loss_avg))\n",
    "            losses = 0\n",
    "            \n",
    "        # save checkpoint\n",
    "        if iteration % save_every == 0:\n",
    "            save_directory = os.path.join(save_dir, '', '{}-{}-{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.sate_dict(),\n",
    "                'loss': loss,\n",
    "                'vocab_dict': vocab.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_checkpoint.tar'.format(iteration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c24044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # forward input through encoder\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        \n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * preset_tokens.index('<SOS>')\n",
    "        \n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_score = token.zeros([0], device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden,\n",
    "                                                          encoder_outputs)\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            \n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            \n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "            \n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff644e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
